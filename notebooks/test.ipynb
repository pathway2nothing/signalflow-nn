{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18caa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alastor/miniconda3/envs/sfnn/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2026-01-07 19:07:14.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msignalflow.data.raw_store.duckdb_stores\u001b[0m:\u001b[36m_ensure_tables\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mDatabase initialized: test.duckdb (timeframe=1m)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (393120, 12) (full history)\n",
      "Feature columns (10): ['rsi_RSI_14', 'macd_12_26_9_MACD_12_26_9', 'macd_12_26_9_MACDh_12_26_9', 'macd_12_26_9_MACDs_12_26_9', 'atr_14_ATRr_14']...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected 393033 total signals\n",
      "Actionable signals: 15854\n",
      "Signal distribution:\n",
      "shape: (2, 2)\n",
      "┌─────────────┬──────┐\n",
      "│ signal_type ┆ len  │\n",
      "│ ---         ┆ ---  │\n",
      "│ str         ┆ u32  │\n",
      "╞═════════════╪══════╡\n",
      "│ rise        ┆ 7928 │\n",
      "│ fall        ┆ 7926 │\n",
      "└─────────────┴──────┘\n",
      "\n",
      "Labeled signals: 15854\n",
      "Label distribution:\n",
      "shape: (3, 2)\n",
      "┌───────┬──────┐\n",
      "│ label ┆ len  │\n",
      "│ ---   ┆ ---  │\n",
      "│ i64   ┆ u32  │\n",
      "╞═══════╪══════╡\n",
      "│ 1     ┆ 8006 │\n",
      "│ 2     ┆ 7788 │\n",
      "│ 0     ┆ 60   │\n",
      "└───────┴──────┘\n",
      "\n",
      "============================================================\n",
      "Starting training\n",
      "============================================================\n",
      "Input size: 10\n",
      "Window size: 30\n",
      "Training on 15854 labeled signals\n",
      "(NOT on all 393120 bars!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alastor/miniconda3/envs/sfnn/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------\n",
      "0 | encoder | LSTMEncoder       | 52.7 K | train | 0    \n",
      "1 | head    | MLPClassifierHead | 16.8 K | train | 0    \n",
      "2 | loss_fn | CrossEntropyLoss  | 0      | train | 0    \n",
      "--------------------------------------------------------------\n",
      "69.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "69.5 K    Total params\n",
      "0.278     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: train=9512, val=3171, test=3171\n",
      "Epoch 0: 100%|██████████| 148/148 [00:01<00:00, 97.55it/s, v_num=4, val_loss=nan.0, val_acc=0.00378, train_loss=nan.0, train_acc=0.00306]\n",
      "\n",
      "Training finished.\n",
      "\n",
      "============================================================\n",
      "VALIDATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Top Rise Signals (high probability):\n",
      "shape: (10, 5)\n",
      "┌─────────────────────┬─────────┬───────────┬───────────┬──────────────┐\n",
      "│ timestamp           ┆ pair    ┆ prob_rise ┆ prob_fall ┆ prob_neutral │\n",
      "│ ---                 ┆ ---     ┆ ---       ┆ ---       ┆ ---          │\n",
      "│ datetime[μs]        ┆ str     ┆ f64       ┆ f64       ┆ f64          │\n",
      "╞═════════════════════╪═════════╪═══════════╪═══════════╪══════════════╡\n",
      "│ 2025-10-01 00:40:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 00:56:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 01:42:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 03:13:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 04:07:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 05:12:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 05:53:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 06:45:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 07:10:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 07:50:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "└─────────────────────┴─────────┴───────────┴───────────┴──────────────┘\n",
      "\n",
      "Top Fall Signals (high probability):\n",
      "shape: (10, 5)\n",
      "┌─────────────────────┬─────────┬───────────┬───────────┬──────────────┐\n",
      "│ timestamp           ┆ pair    ┆ prob_rise ┆ prob_fall ┆ prob_neutral │\n",
      "│ ---                 ┆ ---     ┆ ---       ┆ ---       ┆ ---          │\n",
      "│ datetime[μs]        ┆ str     ┆ f64       ┆ f64       ┆ f64          │\n",
      "╞═════════════════════╪═════════╪═══════════╪═══════════╪══════════════╡\n",
      "│ 2025-10-01 00:45:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 01:35:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 02:19:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 03:43:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 04:53:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 05:34:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 06:01:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 06:51:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 07:45:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "│ 2025-10-01 07:54:00 ┆ BTCUSDT ┆ NaN       ┆ NaN       ┆ NaN          │\n",
      "└─────────────────────┴─────────┴───────────┴───────────┴──────────────┘\n",
      "\n",
      "High-confidence signals (>70%):\n",
      "  Rise signals: 7928\n",
      "  Fall signals: 7926\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/temporal_validator.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 247\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Fall signals: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhigh_conf_fall.height\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# 8. Save Validator\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./models/temporal_validator.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mValidator saved to ./models/temporal_validator.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# To load later:\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# loaded_validator = TemporalValidator.load(Path(\"./models/temporal_validator.pkl\"))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/signalflow-nn/src/signalflow/nn/validator/temporal_validator.py:401\u001b[39m, in \u001b[36mTemporalValidator.save\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    386\u001b[39m path = Path(path)\n\u001b[32m    388\u001b[39m state = {\n\u001b[32m    389\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mencoder_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.encoder_type,\n\u001b[32m    390\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mencoder_params\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.encoder_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    398\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model.state_dict() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    399\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    402\u001b[39m     pickle.dump(state, f)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'models/temporal_validator.pkl'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example: Training TemporalValidator with SignalFlow-NN\n",
    "\n",
    "Flow:\n",
    "1. Load raw data\n",
    "2. Extract features (for ALL bars - this is the feature history)\n",
    "3. Detect signals (generates signal timestamps)\n",
    "4. Label signals (assigns labels ONLY to signal timestamps)\n",
    "5. Train validator (windows created ONLY at signal timestamps)\n",
    "6. Validate new signals\n",
    "\n",
    "Key insight: The dataset contains windows ONLY for detected signals,\n",
    "not for every bar. This is meta-labeling approach.\n",
    "\"\"\"\n",
    "import signalflow as sf\n",
    "from signalflow.nn.validator import TemporalValidator\n",
    "from signalflow.nn.model.temporal_classificator import TrainingConfig\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Load Raw Data\n",
    "# ============================================================================\n",
    "\n",
    "raw_data = sf.data.RawDataFactory.from_duckdb_spot_store(\n",
    "    spot_store_path=Path(\"test.duckdb\"),\n",
    "    pairs=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"],\n",
    "    start=datetime(2025, 10, 1),\n",
    "    end=datetime(2025, 12, 31),\n",
    "    data_types=[\"spot\"],\n",
    ")\n",
    "raw_data_view = sf.core.RawDataView(raw_data)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Feature Engineering (for ALL bars - this is feature history)\n",
    "# ============================================================================\n",
    "\n",
    "feature_set = sf.feature.FeatureSet(extractors=[\n",
    "    sf.feature.pandasta.PandasTaRsiExtractor(length=14),\n",
    "    sf.feature.pandasta.PandasTaMacdExtractor(fast=12, slow=26, signal=9),\n",
    "    sf.feature.pandasta.PandasTaAtrExtractor(length=14),\n",
    "    sf.feature.pandasta.PandasTaBbandsExtractor(length=20, std=2.0),\n",
    "])\n",
    "features_df = feature_set.extract(raw_data_view)\n",
    "\n",
    "# Normalize features per pair\n",
    "feature_cols = [c for c in features_df.columns if c not in [\"pair\", \"timestamp\"]]\n",
    "features_df = features_df.with_columns([\n",
    "    ((pl.col(c) - pl.col(c).mean().over(\"pair\")) / (pl.col(c).std().over(\"pair\") + 1e-6))\n",
    "    .alias(c)\n",
    "    for c in feature_cols\n",
    "])\n",
    "\n",
    "print(f\"Features shape: {features_df.shape} (full history)\")\n",
    "print(f\"Feature columns ({len(feature_cols)}): {feature_cols[:5]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Signal Detection (generates signal TIMESTAMPS)\n",
    "# ============================================================================\n",
    "\n",
    "detector = sf.detector.SmaCrossSignalDetector(fast_period=10, slow_period=30)\n",
    "signals = detector.run(raw_data_view)\n",
    "\n",
    "# Filter to actionable signals only (RISE/FALL, not NONE)\n",
    "actionable_signals = signals.value.filter(\n",
    "    pl.col(\"signal_type\").is_in([\"rise\", \"fall\"])\n",
    ")\n",
    "\n",
    "print(f\"\\nDetected {signals.value.height} total signals\")\n",
    "print(f\"Actionable signals: {actionable_signals.height}\")\n",
    "print(f\"Signal distribution:\\n{actionable_signals.group_by('signal_type').len()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Labeling (assign labels ONLY to signal timestamps)\n",
    "# ============================================================================\n",
    "\n",
    "from signalflow.target import FixedHorizonLabeler\n",
    "\n",
    "labeler = FixedHorizonLabeler(\n",
    "    price_col=\"close\",\n",
    "    horizon=12,\n",
    "    out_col=\"label\",\n",
    "    include_meta=True,\n",
    ")\n",
    "\n",
    "# Label the raw data, then join with signals\n",
    "spot_df = raw_data_view.to_polars(\"spot\")\n",
    "labeled_full = labeler.compute(spot_df)\n",
    "\n",
    "# Join labels with signal timestamps\n",
    "# This gives us labels ONLY for detected signal timestamps\n",
    "labeled_signals = (\n",
    "    actionable_signals\n",
    "    .select([\"pair\", \"timestamp\", \"signal_type\"])\n",
    "    .join(\n",
    "        labeled_full.select([\"pair\", \"timestamp\", \"label\"]),\n",
    "        on=[\"pair\", \"timestamp\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .filter(pl.col(\"label\").is_not_null())\n",
    ")\n",
    "\n",
    "# Encode labels: none=0, rise=1, fall=2\n",
    "labeled_signals = labeled_signals.with_columns(\n",
    "    pl.when(pl.col(\"label\") == \"rise\").then(1)\n",
    "    .when(pl.col(\"label\") == \"fall\").then(2)\n",
    "    .otherwise(0)\n",
    "    .cast(pl.Int64)\n",
    "    .alias(\"label\")\n",
    ")\n",
    "\n",
    "print(f\"\\nLabeled signals: {labeled_signals.height}\")\n",
    "print(f\"Label distribution:\\n{labeled_signals.group_by('label').len()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Configure and Train Validator\n",
    "# ============================================================================\n",
    "\n",
    "input_size = len(feature_cols)\n",
    "\n",
    "# Encoder config\n",
    "encoder_params = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"bidirectional\": False,\n",
    "}\n",
    "\n",
    "# Head config\n",
    "head_params = {\n",
    "    \"hidden_sizes\": [128, 64],\n",
    "    \"dropout\": 0.3,\n",
    "    \"activation\": \"gelu\",\n",
    "}\n",
    "\n",
    "# Training config\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"optimizer\": \"adamw\",\n",
    "    \"scheduler\": \"reduce_on_plateau\",\n",
    "    \"scheduler_patience\": 5,\n",
    "    \"label_smoothing\": 0.1,\n",
    "}\n",
    "\n",
    "# Create validator\n",
    "validator = TemporalValidator(\n",
    "    encoder_type=\"encoder/lstm\",\n",
    "    encoder_params=encoder_params,\n",
    "    head_type=\"head/cls/mlp\",\n",
    "    head_params=head_params,\n",
    "    window_size=30,\n",
    "    num_classes=3,\n",
    "    class_weights=[1.0, 2.0, 2.0],  # Upweight rise/fall\n",
    "    training_config=training_config,\n",
    "    feature_cols=feature_cols,\n",
    "    max_epochs=10,\n",
    "    batch_size=64,\n",
    "    early_stopping_patience=5,\n",
    "    train_val_test_split=(0.6, 0.2, 0.2),\n",
    "    split_strategy=\"temporal\",\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting training\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Input size: {input_size}\")\n",
    "print(f\"Window size: {validator.window_size}\")\n",
    "print(f\"Training on {labeled_signals.height} labeled signals\")\n",
    "print(f\"(NOT on all {features_df.height} bars!)\")\n",
    "\n",
    "# Train: X_train is full feature history, y_train is ONLY labeled signals\n",
    "validator.fit(\n",
    "    X_train=features_df,        # Full feature history\n",
    "    y_train=labeled_signals,    # Only signal timestamps with labels\n",
    "    log_dir=Path(\"./logs/temporal_validator\"),\n",
    "    accelerator=\"auto\",\n",
    ")\n",
    "\n",
    "print(\"\\nTraining finished.\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Validate New Signals\n",
    "# ============================================================================\n",
    "\n",
    "validated_signals = validator.validate_signals(signals, features_df)\n",
    "\n",
    "# Rename probability columns for clarity\n",
    "validated_df = validated_signals.value.with_columns([\n",
    "    pl.col(\"probability_none\").alias(\"prob_neutral\"),\n",
    "    pl.col(\"probability_rise\").alias(\"prob_rise\"),\n",
    "    pl.col(\"probability_fall\").alias(\"prob_fall\"),\n",
    "])\n",
    "\n",
    "# ============================================================================\n",
    "# 7. Analyze Results\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Top Rise Signals\n",
    "print(\"\\nTop Rise Signals (high probability):\")\n",
    "rise_signals = (\n",
    "    validated_df\n",
    "    .filter(pl.col(\"signal_type\") == \"rise\")\n",
    "    .sort(\"prob_rise\", descending=True)\n",
    "    .select([\"timestamp\", \"pair\", \"prob_rise\", \"prob_fall\", \"prob_neutral\"])\n",
    "    .head(10)\n",
    ")\n",
    "print(rise_signals)\n",
    "\n",
    "# Top Fall Signals\n",
    "print(\"\\nTop Fall Signals (high probability):\")\n",
    "fall_signals = (\n",
    "    validated_df\n",
    "    .filter(pl.col(\"signal_type\") == \"fall\")\n",
    "    .sort(\"prob_fall\", descending=True)\n",
    "    .select([\"timestamp\", \"pair\", \"prob_rise\", \"prob_fall\", \"prob_neutral\"])\n",
    "    .head(10)\n",
    ")\n",
    "print(fall_signals)\n",
    "\n",
    "# High-confidence signals (>70% probability)\n",
    "HIGH_CONF_THRESHOLD = 0.7\n",
    "\n",
    "high_conf_rise = validated_df.filter(\n",
    "    (pl.col(\"signal_type\") == \"rise\") & (pl.col(\"prob_rise\") > HIGH_CONF_THRESHOLD)\n",
    ")\n",
    "high_conf_fall = validated_df.filter(\n",
    "    (pl.col(\"signal_type\") == \"fall\") & (pl.col(\"prob_fall\") > HIGH_CONF_THRESHOLD)\n",
    ")\n",
    "\n",
    "print(f\"\\nHigh-confidence signals (>{HIGH_CONF_THRESHOLD*100:.0f}%):\")\n",
    "print(f\"  Rise signals: {high_conf_rise.height}\")\n",
    "print(f\"  Fall signals: {high_conf_fall.height}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. Save Validator\n",
    "# ============================================================================\n",
    "\n",
    "validator.save(Path(\"./models/temporal_validator.pkl\"))\n",
    "print(\"\\nValidator saved to ./models/temporal_validator.pkl\")\n",
    "\n",
    "# To load later:\n",
    "# loaded_validator = TemporalValidator.load(Path(\"./models/temporal_validator.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
