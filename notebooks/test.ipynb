{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18caa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: Training TemporalValidator with SignalFlow-NN\n",
    "\n",
    "Flow:\n",
    "1. Load raw data\n",
    "2. Extract features (RAW values, normalization handled by preprocessor)\n",
    "3. Detect signals\n",
    "4. Label signals\n",
    "5. Configure Preprocessor & Train Validator\n",
    "6. Validate new signals\n",
    "\"\"\"\n",
    "import signalflow as sf\n",
    "from signalflow.nn.validator import TemporalValidator\n",
    "from signalflow.nn.model.temporal_classificator import TrainingConfig\n",
    "from signalflow.nn.data.ts_preprocessor import TimeSeriesPreprocessor, ScalerConfig  # <--- NEW IMPORT\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Load Raw Data\n",
    "# ============================================================================\n",
    "\n",
    "raw_data = sf.data.RawDataFactory.from_duckdb_spot_store(\n",
    "    spot_store_path=Path(\"test.duckdb\"),\n",
    "    pairs=[\"SOLUSDT\"],\n",
    "    start=datetime(2025, 1, 1),\n",
    "    end=datetime(2025, 12, 31),\n",
    "    data_types=[\"spot\"],\n",
    ")\n",
    "raw_data_view = sf.core.RawDataView(raw_data)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Feature Engineering\n",
    "# ============================================================================\n",
    "\n",
    "feature_set = sf.feature.FeatureSet(extractors=[\n",
    "    sf.feature.pandasta.PandasTaRsiExtractor(length=14),\n",
    "    sf.feature.pandasta.PandasTaMacdExtractor(fast=12, slow=26, signal=9),\n",
    "    sf.feature.pandasta.PandasTaAtrExtractor(length=14),\n",
    "    sf.feature.pandasta.PandasTaBbandsExtractor(length=20, std=2.0),\n",
    "])\n",
    "features_df = feature_set.extract(raw_data_view)\n",
    "\n",
    "# Визначаємо список колонок (але НЕ нормалізуємо тут вручну)\n",
    "feature_cols = [c for c in features_df.columns if c not in [\"pair\", \"timestamp\"]]\n",
    "\n",
    "print(f\"Features shape: {features_df.shape} (full history, RAW values)\")\n",
    "print(f\"Feature columns ({len(feature_cols)}): {feature_cols[:5]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Signal Detection\n",
    "# ============================================================================\n",
    "\n",
    "detector = sf.detector.SmaCrossSignalDetector(fast_period=10, slow_period=30)\n",
    "signals = detector.run(raw_data_view)\n",
    "\n",
    "# Filter to actionable signals only\n",
    "actionable_signals = signals.value.filter(\n",
    "    pl.col(\"signal_type\").is_in([\"rise\", \"fall\"])\n",
    ")\n",
    "\n",
    "print(f\"\\nDetected {signals.value.height} total signals\")\n",
    "print(f\"Actionable signals: {actionable_signals.height}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Labeling\n",
    "# ============================================================================\n",
    "\n",
    "from signalflow.target import FixedHorizonLabeler\n",
    "\n",
    "labeler = FixedHorizonLabeler(\n",
    "    price_col=\"close\",\n",
    "    horizon=120,\n",
    "    out_col=\"label\",\n",
    "    include_meta=True,\n",
    ")\n",
    "\n",
    "spot_df = raw_data_view.to_polars(\"spot\")\n",
    "labeled_full = labeler.compute(spot_df)\n",
    "\n",
    "labeled_signals = (\n",
    "    actionable_signals\n",
    "    .select([\"pair\", \"timestamp\", \"signal_type\"])\n",
    "    .join(\n",
    "        labeled_full.select([\"pair\", \"timestamp\", \"label\"]),\n",
    "        on=[\"pair\", \"timestamp\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .filter(pl.col(\"label\").is_not_null())\n",
    ")\n",
    "\n",
    "labeled_signals = labeled_signals.with_columns(\n",
    "    pl.when(pl.col(\"label\") == \"rise\").then(1)\n",
    "    .when(pl.col(\"label\") == \"fall\").then(2)\n",
    "    .otherwise(0)\n",
    "    .cast(pl.Int64)\n",
    "    .alias(\"label\")\n",
    ")\n",
    "\n",
    "print(f\"\\nLabeled signals: {labeled_signals.height}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Configure and Train Validator (WITH PREPROCESSOR)\n",
    "# ============================================================================\n",
    "\n",
    "input_size = len(feature_cols)\n",
    "\n",
    "# Encoder config\n",
    "encoder_params = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"bidirectional\": False,\n",
    "}\n",
    "\n",
    "# Head config\n",
    "head_params = {\n",
    "    \"hidden_sizes\": [128, 64],\n",
    "    \"dropout\": 0.3,\n",
    "    \"activation\": \"gelu\",\n",
    "}\n",
    "\n",
    "# Training config\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"optimizer\": \"adamw\",\n",
    "    \"scheduler\": \"reduce_on_plateau\",\n",
    "    \"scheduler_patience\": 5,\n",
    "    \"label_smoothing\": 0.1,\n",
    "}\n",
    "\n",
    "# --- NEW: Configure Preprocessor ---\n",
    "# Автоматична нормалізація (Robust) по кожній групі (парі) окремо\n",
    "preprocessor = TimeSeriesPreprocessor(\n",
    "    default_config=ScalerConfig(method=\"robust\", scope=\"group\"),\n",
    "    group_col=\"pair\",\n",
    "    time_col=\"timestamp\"\n",
    ")\n",
    "# -----------------------------------\n",
    "\n",
    "# Create validator\n",
    "validator = TemporalValidator(\n",
    "    encoder_type=\"encoder/gru\",\n",
    "    encoder_params=encoder_params,\n",
    "    head_type=\"head/cls/linear\",\n",
    "    head_params=head_params,\n",
    "    \n",
    "    preprocessor=preprocessor,  # <--- CONNECTED HERE\n",
    "    \n",
    "    window_size=30,\n",
    "    num_classes=3,\n",
    "    class_weights=[1.0, 1.0, 1.0],\n",
    "    training_config=training_config,\n",
    "    feature_cols=feature_cols,\n",
    "    max_epochs=100,\n",
    "    batch_size=64,\n",
    "    early_stopping_patience=5,\n",
    "    train_val_test_split=(0.6, 0.2, 0.2),\n",
    "    split_strategy=\"temporal\",\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting training\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# fit() now handles scaling internally (fit on train -> transform all)\n",
    "validator.fit(\n",
    "    X_train=features_df,      \n",
    "    y_train=labeled_signals,    \n",
    "    log_dir=Path(\"./logs/temporal_validator\"),\n",
    "    accelerator=\"auto\",\n",
    ")\n",
    "\n",
    "print(\"\\nTraining finished.\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Validate New Signals\n",
    "# ============================================================================\n",
    "\n",
    "# Features are automatically scaled using the saved preprocessor state\n",
    "validated_signals = validator.validate_signals(signals, features_df)\n",
    "\n",
    "validated_df = validated_signals.value.with_columns([\n",
    "    pl.col(\"probability_none\").alias(\"prob_neutral\"),\n",
    "    pl.col(\"probability_rise\").alias(\"prob_rise\"),\n",
    "    pl.col(\"probability_fall\").alias(\"prob_fall\"),\n",
    "])\n",
    "\n",
    "# ============================================================================\n",
    "# 7. Analyze Results\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Top Rise Signals\n",
    "print(\"\\nTop Rise Signals (high probability):\")\n",
    "rise_signals = (\n",
    "    validated_df\n",
    "    .filter(pl.col(\"signal_type\") == \"rise\")\n",
    "    .sort(\"prob_rise\", descending=True)\n",
    "    .select([\"timestamp\", \"pair\", \"prob_rise\", \"prob_fall\", \"prob_neutral\"])\n",
    "    .head(10)\n",
    ")\n",
    "print(rise_signals)\n",
    "\n",
    "# High-confidence signals (>70% probability)\n",
    "HIGH_CONF_THRESHOLD = 0.7\n",
    "high_conf_rise = validated_df.filter(\n",
    "    (pl.col(\"signal_type\") == \"rise\") & (pl.col(\"prob_rise\") > HIGH_CONF_THRESHOLD)\n",
    ")\n",
    "\n",
    "print(f\"\\nHigh-confidence signals (>{HIGH_CONF_THRESHOLD*100:.0f}%):\")\n",
    "print(f\"  Rise signals: {high_conf_rise.height}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. Save Validator\n",
    "# ============================================================================\n",
    "\n",
    "validator.save(Path(\"./best_models/temporal_validator.pkl\"))\n",
    "print(\"\\nValidator saved to ./models/temporal_validator.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
