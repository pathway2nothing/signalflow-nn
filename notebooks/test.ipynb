{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18caa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: Training TemporalValidator with SignalFlow-NN\n",
    "\n",
    "Demonstrates the new config-based API for TemporalClassificator.\n",
    "\"\"\"\n",
    "import signalflow as sf\n",
    "from signalflow.nn.validator import TemporalValidator\n",
    "from signalflow.nn.model.temporal_classificator import TrainingConfig\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Load Raw Data\n",
    "# ============================================================================\n",
    "\n",
    "spot_store = sf.data.raw_store.DuckDbSpotStore(db_path=Path(\"test.duckdb\"))\n",
    "raw_data = sf.data.RawDataFactory.from_duckdb_spot_store(\n",
    "    spot_store_path=Path(\"test.duckdb\"),\n",
    "    pairs=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"],\n",
    "    start=datetime(2025, 10, 1),\n",
    "    end=datetime(2025, 12, 31),\n",
    "    data_types=[\"spot\"],\n",
    ")\n",
    "raw_data_view = sf.core.RawDataView(raw_data)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Feature Engineering\n",
    "# ============================================================================\n",
    "\n",
    "feature_set = sf.feature.FeatureSet(extractors=[\n",
    "    sf.feature.pandasta.PandasTaRsiExtractor(length=14),\n",
    "    sf.feature.pandasta.PandasTaMacdExtractor(fast=12, slow=26, signal=9),\n",
    "    sf.feature.pandasta.PandasTaAtrExtractor(length=14),\n",
    "    sf.feature.pandasta.PandasTaBbandsExtractor(length=20, std=2.0),\n",
    "])\n",
    "features_df = feature_set.extract(raw_data_view)\n",
    "\n",
    "# Normalize features per pair\n",
    "feature_cols = [c for c in features_df.columns if c not in [\"pair\", \"timestamp\"]]\n",
    "features_df = features_df.with_columns([\n",
    "    ((pl.col(c) - pl.col(c).mean().over(\"pair\")) / (pl.col(c).std().over(\"pair\") + 1e-6))\n",
    "    .alias(c)\n",
    "    for c in feature_cols\n",
    "])\n",
    "\n",
    "print(f\"Features shape: {features_df.shape}\")\n",
    "print(f\"Feature columns: {feature_cols}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Signal Detection\n",
    "# ============================================================================\n",
    "\n",
    "detector = sf.detector.SmaCrossSignalDetector(fast_period=10, slow_period=30)\n",
    "signals = detector.run(raw_data_view)\n",
    "\n",
    "print(f\"Detected {signals.value.height} signals\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Labeling (Ground Truth)\n",
    "# ============================================================================\n",
    "\n",
    "from signalflow.target import FixedHorizonLabeler\n",
    "\n",
    "labeler = FixedHorizonLabeler(\n",
    "    price_col=\"close\",\n",
    "    horizon=12,\n",
    "    out_col=\"label\",\n",
    "    include_meta=True,\n",
    ")\n",
    "labeled_df = labeler.compute(raw_data_view.to_polars(\"spot\"), signals)\n",
    "\n",
    "\n",
    "def encode_labels(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Encode labels: none=0, rise=1, fall=2\"\"\"\n",
    "    return df.with_columns(\n",
    "        pl.when(pl.col(\"label\") == \"rise\").then(1)\n",
    "        .when(pl.col(\"label\") == \"fall\").then(2)\n",
    "        .otherwise(0)\n",
    "        .cast(pl.Int64)\n",
    "        .alias(\"label\")\n",
    "    )\n",
    "\n",
    "\n",
    "# Join labeled_df with signals to get signal_type\n",
    "train_signals_df = (\n",
    "    encode_labels(labeled_df)\n",
    "    .join(\n",
    "        signals.value.select([\"pair\", \"timestamp\", \"signal_type\"]),\n",
    "        on=[\"pair\", \"timestamp\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .select([\"pair\", \"timestamp\", \"label\", \"signal_type\"])\n",
    "    .filter(pl.col(\"label\").is_not_null())\n",
    ")\n",
    "\n",
    "print(f\"Training signals: {train_signals_df.height}\")\n",
    "print(f\"Label distribution:\\n{train_signals_df.group_by('label').len()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Configure and Train Validator\n",
    "# ============================================================================\n",
    "\n",
    "# Determine input size from features\n",
    "input_size = len(feature_cols)\n",
    "\n",
    "# Encoder config (LSTM)\n",
    "encoder_params = {\n",
    "    \"input_size\": input_size,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"bidirectional\": False,\n",
    "}\n",
    "\n",
    "# Head config (MLP classifier)\n",
    "head_params = {\n",
    "    \"hidden_sizes\": [128, 64],\n",
    "    \"dropout\": 0.3,\n",
    "    \"activation\": \"gelu\",\n",
    "}\n",
    "\n",
    "# Training config (separate from architecture)\n",
    "training_config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"optimizer\": \"adamw\",\n",
    "    \"scheduler\": \"reduce_on_plateau\",\n",
    "    \"scheduler_patience\": 5,\n",
    "    \"label_smoothing\": 0.1,\n",
    "}\n",
    "\n",
    "# Create validator with new API\n",
    "validator = TemporalValidator(\n",
    "    # Architecture\n",
    "    encoder_type=\"encoder/lstm\",\n",
    "    encoder_params=encoder_params,\n",
    "    head_type=\"head/cls/mlp\",\n",
    "    head_params=head_params,\n",
    "    \n",
    "    # Model settings\n",
    "    window_size=30,\n",
    "    num_classes=3,\n",
    "    class_weights=[1.0, 2.0, 2.0],  # Upweight rise/fall vs neutral\n",
    "    training_config=training_config,\n",
    "    feature_cols=feature_cols,\n",
    "    \n",
    "    # Training settings\n",
    "    max_epochs=10,\n",
    "    batch_size=64,\n",
    "    early_stopping_patience=5,\n",
    "    train_val_test_split=(0.6, 0.2, 0.2),\n",
    "    split_strategy=\"temporal\",\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"\\nStarting training on {train_signals_df.height} signals...\")\n",
    "print(f\"Input size: {input_size}, Window size: {validator.window_size}\")\n",
    "\n",
    "# Train\n",
    "validator.fit(\n",
    "    X_train=features_df,\n",
    "    y_train=train_signals_df,\n",
    "    log_dir=Path(\"./logs/temporal_validator\"),\n",
    "    accelerator=\"auto\",\n",
    ")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Validate New Signals\n",
    "# ============================================================================\n",
    "\n",
    "validated_signals = validator.validate_signals(signals, features_df)\n",
    "\n",
    "# Rename probability columns for clarity\n",
    "validated_df = validated_signals.value.with_columns([\n",
    "    pl.col(\"probability_none\").alias(\"prob_neutral\"),\n",
    "    pl.col(\"probability_rise\").alias(\"prob_rise\"),\n",
    "    pl.col(\"probability_fall\").alias(\"prob_fall\"),\n",
    "])\n",
    "\n",
    "# ============================================================================\n",
    "# 7. Analyze Results\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Top Rise Signals\n",
    "print(\"\\nTop Rise Signals (high probability):\")\n",
    "rise_signals = (\n",
    "    validated_df\n",
    "    .filter(pl.col(\"signal_type\") == \"rise\")\n",
    "    .sort(\"prob_rise\", descending=True)\n",
    "    .select([\"timestamp\", \"pair\", \"prob_rise\", \"prob_fall\", \"prob_neutral\"])\n",
    "    .head(10)\n",
    ")\n",
    "print(rise_signals)\n",
    "\n",
    "# Top Fall Signals\n",
    "print(\"\\nTop Fall Signals (high probability):\")\n",
    "fall_signals = (\n",
    "    validated_df\n",
    "    .filter(pl.col(\"signal_type\") == \"fall\")\n",
    "    .sort(\"prob_fall\", descending=True)\n",
    "    .select([\"timestamp\", \"pair\", \"prob_rise\", \"prob_fall\", \"prob_neutral\"])\n",
    "    .head(10)\n",
    ")\n",
    "print(fall_signals)\n",
    "\n",
    "# High-confidence signals (>70% probability)\n",
    "HIGH_CONF_THRESHOLD = 0.7\n",
    "\n",
    "high_conf_rise = validated_df.filter(\n",
    "    (pl.col(\"signal_type\") == \"rise\") & (pl.col(\"prob_rise\") > HIGH_CONF_THRESHOLD)\n",
    ")\n",
    "high_conf_fall = validated_df.filter(\n",
    "    (pl.col(\"signal_type\") == \"fall\") & (pl.col(\"prob_fall\") > HIGH_CONF_THRESHOLD)\n",
    ")\n",
    "\n",
    "print(f\"\\nHigh-confidence signals (>{HIGH_CONF_THRESHOLD*100:.0f}%):\")\n",
    "print(f\"  Rise signals: {high_conf_rise.height}\")\n",
    "print(f\"  Fall signals: {high_conf_fall.height}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. Save Validator\n",
    "# ============================================================================\n",
    "\n",
    "validator.save(Path(\"./models/temporal_validator.pkl\"))\n",
    "print(\"\\nValidator saved to ./models/temporal_validator.pkl\")\n",
    "\n",
    "# To load later:\n",
    "# loaded_validator = TemporalValidator.load(Path(\"./models/temporal_validator.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
